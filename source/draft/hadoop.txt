http://www.powerxing.com/install-hadoop/
http://www.polarxiong.com/archives/%E5%AE%89%E8%A3%85Hadoop-2-7-2%E4%BC%AA%E5%88%86%E5%B8%83%E6%A8%A1%E5%BC%8F%E5%88%B0Ubuntu-16-04%E6%95%99%E7%A8%8B.html

sudo apt update
忽略:1 http://dl.google.com/linux/chrome/deb stable InRelease
获取:2 http://archive.ubuntukylin.com:10006/ubuntukylin xenial InRelease [3,192 B]
命中:3 http://cn.archive.ubuntu.com/ubuntu xenial InRelease                    
错误:2 http://archive.ubuntukylin.com:10006/ubuntukylin xenial InRelease       
  由于没有公钥，无法验证下列签名： NO_PUBKEY 8D5A09DC9B929006
命中:4 http://cn.archive.ubuntu.com/ubuntu xenial-updates InRelease            
获取:5 http://cn.archive.ubuntu.com/ubuntu xenial-backports InRelease [92.2 kB]
命中:6 http://security.ubuntu.com/ubuntu xenial-security InRelease             
命中:7 http://dl.google.com/linux/chrome/deb stable Release              
正在读取软件包列表... 完成    
W: GPG 错误：http://archive.ubuntukylin.com:10006/ubuntukylin xenial InRelease: 由于没有公钥，无法验证下列签名： NO_PUBKEY 8D5A09DC9B929006
E: 仓库 “http://archive.ubuntukylin.com:10006/ubuntukylin xenial InRelease” 没有数字签名。
N: 无法安全地用该源进行更新，所以默认禁用该源。
N: 参见 apt-secure(8) 手册以了解仓库创建和用户配置方面的细节。

sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 8D5A09DC9B929006


sudo apt install openssh-server -y
ssh localhost
输入密码可以登陆

exit
ssh-keygen -t rsa 一路回车，不要输入任何东西
cat id_rsa.pub >> authorized_keys

配置jdk
原来的用户已经安装过了，只需要在`.bashrc`中设置路径就行

```
export JAVA_HOME=/usr/dev/jdk1.7.0_40
export JRE_HOME=${JAVA_HOME}/jre
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
export PATH=${JAVA_HOME}/bin:$PATH
```
解压
sudo tar -xvf /home/junqiangshen/模板/env_backup/software/hadoop-2.6.4.tar.gz -C /usr/dev/
sudo chown -R hadoop /usr/dev/hadoop-2.6.4/


hadoop@junqiang:/usr/dev/hadoop-2.6.4$ ./bin/hadoop version
Hadoop 2.6.4
Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r 5082c73637530b0b7e115f9625ed7fac69f937e6
Compiled by jenkins on 2016-02-12T09:45Z
Compiled with protoc 2.5.0
From source with checksum 8dee2286ecdbbbc930a6c87b65cbc010
This command was run using /usr/dev/hadoop-2.6.4/share/hadoop/common/hadoop-common-2.6.4.jar


单机配置
mkdir input
hadoop@junqiang:/usr/dev/hadoop-2.6.4$ cp etc/hadoop/*.xml input/
./bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar grep input/ output 'dfs[a-z.]+'
hadoop@junqiang:/usr/dev/hadoop-2.6.4$ cat output/*
1	dfsadmin


修改
etc/hadoop/core-site.xml
<configuration>
  <property>
    <name>hadoop.tmp.dir</name>
    <value>file:/usr/dev/hadoop-2.6.4/tmp</value>
    <description>Abase for other temporary directories.</description>
  </property>
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://localhost:9000</value>
  </property>
</configuration>

etc/hadoop/hdfs-site.xml
<configuration>
  <property>
    <name>dfs.replication</name>
    <value>1</value>
  </property>
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>file:/usr/dev/hadoop-2.6.4/tmp/dfs/name</value>
  </property>
  <property>
    <name>dfs.datanode.data.dir</name>
    <value>file:/usr/dev/hadoop-2.6.4/tmp/dfs/data</value>
  </property>
</configuration>

hadoop@junqiang:/usr/dev/hadoop-2.6.4$ ./bin/hdfs namenode -format
............
16/07/19 16:23:54 INFO common.Storage: Storage directory /usr/dev/hadoop-2.6.4/tmp/dfs/name has been successfully formatted.
16/07/19 16:23:54 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0
16/07/19 16:23:54 INFO util.ExitUtil: Exiting with status 0
16/07/19 16:23:54 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at junqiang.shen/127.0.1.1
************************************************************/

hadoop@junqiang:/usr/dev/hadoop-2.6.4$ ./sbin/start-dfs.sh 
Starting namenodes on [localhost]
localhost: Error: JAVA_HOME is not set and could not be found.
localhost: Error: JAVA_HOME is not set and could not be found.
Starting secondary namenodes [0.0.0.0]
0.0.0.0: Error: JAVA_HOME is not set and could not be found.

sudo vim etc/hadoop/hadoop-env.sh 
把对应java_home设置成本机绝对路径

hadoop@junqiang:/usr/dev/hadoop-2.6.4$ ./sbin/start-dfs.sh 
Starting namenodes on [localhost]
localhost: starting namenode, logging to /usr/dev/hadoop-2.6.4/logs/hadoop-hadoop-namenode-junqiang.out
localhost: starting datanode, logging to /usr/dev/hadoop-2.6.4/logs/hadoop-hadoop-datanode-junqiang.out
Starting secondary namenodes [0.0.0.0]
0.0.0.0: starting secondarynamenode, logging to /usr/dev/hadoop-2.6.4/logs/hadoop-hadoop-secondarynamenode-junqiang.out

hadoop@junqiang:/usr/dev/hadoop-2.6.4$ jps
19407 SecondaryNameNode
19239 DataNode
19104 NameNode
19574 Jps

没有NameNode或者`DataNode`则`NameNode`则不对
http://localhost:50070/

伪分布式
doop@junqiang:/usr/dev/hadoop-2.6.4$ ./bin/hdfs dfs -mkdir -p /user/hadoop
hadoop@junqiang:/usr/dev/hadoop-2.6.4$ ./bin/hdfs dfs -mkdir input
hadoop@junqiang:/usr/dev/hadoop-2.6.4$ ./bin/hdfs dfs -put etc/hadoop/*.xml input/

hadoop@junqiang:/usr/dev/hadoop-2.6.4$ ./bin/hdfs dfs -ls input/
Found 8 items
-rw-r--r--   1 hadoop supergroup       4436 2016-07-19 19:37 input/capacity-scheduler.xml
-rw-r--r--   1 hadoop supergroup       1051 2016-07-19 19:37 input/core-site.xml
-rw-r--r--   1 hadoop supergroup       9683 2016-07-19 19:37 input/hadoop-policy.xml
-rw-r--r--   1 hadoop supergroup       1105 2016-07-19 19:37 input/hdfs-site.xml
-rw-r--r--   1 hadoop supergroup        620 2016-07-19 19:37 input/httpfs-site.xml
-rw-r--r--   1 hadoop supergroup       3523 2016-07-19 19:37 input/kms-acls.xml
-rw-r--r--   1 hadoop supergroup       5511 2016-07-19 19:37 input/kms-site.xml
-rw-r--r--   1 hadoop supergroup        690 2016-07-19 19:37 input/yarn-site.xml

./bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar grep input/ output 'dfs[a-z.]+'

查看结果
hadoop@junqiang:/usr/dev/hadoop-2.6.4$ ./bin/hdfs dfs -cat output/*

如果本地有文件`output`,先删除
rm -r output

取回本地
hadoop@junqiang:/usr/dev/hadoop-2.6.4$ ./bin/hdfs dfs -get output output

查看本地内容
hadoop@junqiang:/usr/dev/hadoop-2.6.4$ cat output/*

停止运行
./sbin/stop-dfs.sh

启动Yarn
hadoop@junqiang:/usr/dev/hadoop-2.6.4$ cp etc/hadoop/mapred-site.xml.template etc/hadoop/mapred-site.xml


编辑  etc/hadoop/mapred-site.xml
```
<configuration>
  <property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
  </property>
</configuration>
```

编辑 etc/hadoop/yarn-site.xml
```
<configuration>
<!-- Site specific YARN configuration properties -->
  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
  </property>
</configuration>
```

启动资源管理器
hadoop@junqiang:/usr/dev/hadoop-2.6.4$ ./sbin/start-yarn.sh 
hadoop@junqiang:/usr/dev/hadoop-2.6.4$ ./sbin/mr-jobhistory-daemon.sh start historyserver

http://localhost:8088/cluster
关闭资源你管理器
./sbin/stop-yarn.sh
./sbin/mr-jobhistory-daemon.sh stop historyserver


